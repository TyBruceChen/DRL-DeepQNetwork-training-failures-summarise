{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "#env = gym.make('Acrobot-v1')\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if GPU is to be used\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A glip at the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env Reset State:(array([-0.0129274 ,  0.02088781, -0.01700742,  0.02348842], dtype=float32), {}), Action Choices:Discrete(2), Sample Action:0\n",
      "Sampled Env Return:(array([-0.01250965, -0.17398615, -0.01653765,  0.31075716], dtype=float32), 1.0, False, False, {})\n",
      "Terminated state:True Truncated state:False #29\n"
     ]
    }
   ],
   "source": [
    "print('Env Reset State:{}, Action Choices:{}, Sample Action:{}'\\\n",
    "      .format(env.reset(), env.action_space, env.action_space.sample()))\n",
    "\n",
    "print('Sampled Env Return:{}'.format(env.step(env.action_space.sample())))\n",
    "for i in count():\n",
    "    state, reward, terminated, truncated, _ = env.step(env.action_space.sample())\n",
    "    if terminated == True or truncated == True:\n",
    "        print('Terminated state:{} Truncated state:{} #{}'.format(terminated, truncated, i))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition_tuple = namedtuple('Transition',['state', 'action','next_state','reward'])\n",
    "\n",
    "class Replay_buffer:\n",
    "    def __init__(self, max_capacity=10000):\n",
    "        self.memory = deque([],maxlen = max_capacity)\n",
    "    \n",
    "    def push(self, *args):  #add a new sample\n",
    "        self.memory.append(Transition_tuple(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "memory_buffer = Replay_buffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_set = [a for a in range(env.action_space.n)]\n",
    "DECAY_FACTOR = 0.9\n",
    "DECAY_END = 0.05\n",
    "DECAY_EPS = 1000\n",
    "state_dtype = torch.float32\n",
    "\n",
    "class epsilon_greedy_policy():\n",
    "    def __init__(self, decay_factor, decay_end, decay_eps):\n",
    "        self.decay_factor = decay_factor\n",
    "        self.decay_end = decay_end  #minimium probability of epsilon greedy policy\n",
    "        self.decay_eps = decay_eps\n",
    "        self.reset()\n",
    "    \n",
    "    def take_action(self, Q_estimation, state, verbose = False):\n",
    "        random_value = random.random()\n",
    "        if random_value < self.decay_value :\n",
    "            action = self.take_action_random()\n",
    "        else:   #Q-learning feature\n",
    "            action = self.take_action_policy(Q_estimation, state, verbose)\n",
    "        self.decay_value_update()\n",
    "        return action\n",
    "    \n",
    "    def take_action_random(self):\n",
    "        action = env.action_space.sample()\n",
    "        return action \n",
    "    \n",
    "    def take_action_policy(self, Q_estimation,state, verbose = False):\n",
    "        with torch.no_grad():\n",
    "                Q_value = Q_estimation(torch.tensor(state, dtype=state_dtype).unsqueeze(0))\n",
    "                action_idx = Q_value.argmax()  #in Q-learning, the action with maximum\n",
    "                action = action_set[action_idx]\n",
    "                if verbose == True:\n",
    "                    print('Network Q_values: {}'.format(Q_value))\n",
    "        return action\n",
    "\n",
    "    def decay_value_update(self):\n",
    "        self.taken_steps += 1\n",
    "        self.decay_value = self.decay_end + (self.decay_factor - self.decay_end) * math.exp(-1*self.taken_steps/self.decay_eps)\n",
    "\n",
    "    def reset(self):\n",
    "        self.decay_value = self.decay_factor\n",
    "        self.taken_steps = 0\n",
    "\n",
    "action_policy = epsilon_greedy_policy(DECAY_FACTOR,DECAY_END,DECAY_EPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []\n",
    "step_loss = []\n",
    "def plot_durations(episode_durations = [], show_result=False, plot_mode = 'rewards'):\n",
    "    if plot_mode == 'rewards':\n",
    "        plt.figure(1)\n",
    "    else:\n",
    "        plt.figure(2)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    if plot_mode == 'rewards':\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Duration')\n",
    "    else:\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel('Batch Ave Loss')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "num_observations = env.observation_space.shape[0]\n",
    "num_actions = int(env.action_space.n)\n",
    "\n",
    "if torch.cuda.is_available() or torch.backends.mps.is_available():\n",
    "    num_episodes = 600\n",
    "else:\n",
    "    num_episodes = 1200\n",
    "\n",
    "target_net = DQN(n_observations = num_observations, n_actions = num_actions).to(device = device)\n",
    "policy_net = DQN(n_observations = num_observations, n_actions = num_actions).to(device = device)\n",
    "\n",
    "#policy_net = torch.load('DQN_clamp100.pt')  #fine-tuning from pre-trained model\n",
    "\n",
    "target_net.load_state_dict(policy_net.state_dict()) #create and synchronize the parameters of policy and target model\n",
    "\n",
    "\n",
    "#for param in target_net.parameters():\n",
    "#    param.requires_grad= False\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(),lr = LR, amsgrad = True)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "#criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0778,  0.0658,  0.3126,  0.4329,  0.3312], grad_fn=<SliceBackward0>)\n",
      "tensor([-0.0778,  0.0658,  0.3126,  0.4329,  0.3312], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(target_net.layer1.bias[:5])\n",
    "print(policy_net.layer1.bias[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "state_dtype = torch.float32\n",
    "reward_dtype = torch.int16\n",
    "GAMMA = 0.99\n",
    "TAU = 0.05\n",
    "Alpha = 1\n",
    "operation = 'train'\n",
    "#plot_mode = 'rewards'\n",
    "plot_mode = 'rewards'\n",
    "memory_buffer = Replay_buffer()\n",
    "\n",
    "total_step = 0\n",
    "def model_train():\n",
    "    if len(memory_buffer) <= BATCH_SIZE:\n",
    "        return 0\n",
    "    batch = memory_buffer.sample(BATCH_SIZE)  #a list was return, use special * operator to unpack when feeding into function\n",
    "    #the return value is like [#step1: (state, action, next_state, reward), #step2 ...,] we need to convert them into model-friendly format\n",
    "    ## state: [#step1, #step2], action: [#1,#2,], ... and for convience, we can capsulate them with names by namedtuple\n",
    "    batch = Transition_tuple(*zip(*batch))\n",
    "    #print(batch.state)\n",
    "    state = torch.tensor(batch.state,dtype = state_dtype)\n",
    "    next_state = batch.next_state\n",
    "    reward = torch.tensor(batch.reward, dtype = reward_dtype)\n",
    "\n",
    "    mask_fun = lambda s: True if s is not None else False   #lambda function defined to check whether it's terminated state\n",
    "    next_state_mask = list(map(mask_fun, next_state))   #has to be list, rather than tuple\n",
    "    #print(next_state)\n",
    "    #print(len(next_state))\n",
    "    non_zero_next_state = torch.tensor(next_state, dtype = state_dtype)[next_state_mask]   #mannually set the terminated state to [0,0,...]\n",
    "    next_Q_values = torch.zeros(BATCH_SIZE)\n",
    "\n",
    "    policy_net.train()\n",
    "    optimizer.zero_grad()\n",
    "    current_Q_values = policy_net(state).max(1).values\n",
    "    with torch.no_grad():\n",
    "        next_Q_values[next_state_mask] = target_net(non_zero_next_state).max(1).values #by definition of MDP, the rewards of terminated (final) state should be 0\n",
    "        \n",
    "    \n",
    "    #temporal_differential_error = reward + GAMMA*next_Q_values - current_Q_values\n",
    "    expected_rewards = reward + GAMMA*next_Q_values\n",
    "    \n",
    "    loss = criterion(Alpha*current_Q_values, Alpha*expected_rewards)\n",
    "    loss.backward()\n",
    "\n",
    "    #print('Loss:{}'.format(loss))\n",
    "    #print(f'Target Q value:{expected_rewards}, current Q value:{current_Q_values}')\n",
    "    #print(loss)\n",
    "\n",
    "    #torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)   #limit the gradient value\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)   #clamp: min(max(input, min_value), max_value)\n",
    "    optimizer.step()\n",
    "    return loss.detach().numpy()\n",
    "\n",
    "\n",
    "def train():\n",
    "    state, _info = env.reset()\n",
    "    max_cumulated_reward = 0\n",
    "    for i in range(num_episodes):\n",
    "    # action generation for replay buffer\n",
    "        cumulated_reward = 0\n",
    "        for j in count():\n",
    "            \n",
    "            action = action_policy.take_action(Q_estimation = policy_net, state = state)\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            if terminated == True or truncated:\n",
    "                next_state = [0. for i in range(env.observation_space.shape[0])]\n",
    "            #mul_fun = lambda x: x*100\n",
    "            #state = list(map(mul_fun, state))\n",
    "            #next_state = list(map(mul_fun, next_state))\n",
    "            if terminated == True:\n",
    "                reward = -15  #choose the skewed value for terminate (penalty)\n",
    "            memory_buffer.push(*[state, action, next_state, reward])\n",
    "\n",
    "    # batch sampling from memory for model training\n",
    "            return_loss = model_train()\n",
    "\n",
    "            cumulated_reward += reward\n",
    "            \n",
    "\n",
    "            if terminated == True or truncated == True:\n",
    "                state, _info = env.reset()\n",
    "                if cumulated_reward >= max_cumulated_reward:\n",
    "                    max_cumulated_reward = cumulated_reward\n",
    "                    torch.save(policy_net, 'DQN{}.pt'.format(i))\n",
    "                break\n",
    "            else:\n",
    "                state = next_state\n",
    "            if plot_mode != 'rewards':\n",
    "                step_loss.append(return_loss)   #plot each step's loss (batch average)\n",
    "\n",
    "                \n",
    "        episode_durations.append(cumulated_reward)  #plot with each episode's cumulated reward\n",
    "        if plot_mode == 'rewards':\n",
    "            plot_durations(episode_durations = episode_durations)\n",
    "        else:\n",
    "            plot_durations(episode_durations = step_loss, plot_mode = 'loss')\n",
    "             \n",
    "\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_parameters = policy_net.state_dict()\n",
    "\n",
    "        for key in target_net_state_dict.keys():\n",
    "            target_net_state_dict[key] = policy_net_parameters[key] * TAU + target_net_state_dict[key]*(1-TAU)\n",
    "\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "        \n",
    "train()\n",
    "env.close()\n",
    "print('Complete')\n",
    "if plot_mode == 'rewards':\n",
    "    plot_durations(episode_durations = episode_durations, show_result=True)\n",
    "else:\n",
    "    plot_durations(episode_durations = episode_durations, show_result=True)\n",
    "    plot_durations(episode_durations = step_loss, show_result= True, plot_mode = 'loss')\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0016, -0.1198,  1.1495, -0.0483],\n",
      "        [ 0.4490,  0.0447, -0.5459, -0.0260],\n",
      "        [-0.2017,  0.0221,  0.2201, -0.1453],\n",
      "        [-0.0692,  0.1028,  0.1359,  0.1096],\n",
      "        [-0.0752,  0.0057,  0.0466,  0.0800]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.4796e-03,  6.0482e-03,  5.3161e-04,  6.2154e-03],\n",
      "        [ 1.6032e-02,  3.3631e-02,  1.0520e-03, -4.4497e-03],\n",
      "        [-5.7099e-02, -1.0369e-01,  7.1369e-04,  2.4184e-02],\n",
      "        [-4.7789e-02, -7.8099e-02, -1.4425e-05,  1.2007e-02],\n",
      "        [-4.6336e-02, -7.5795e-02,  8.5686e-05,  1.1793e-02]])\n",
      "tensor([[ 9.4796e-03,  6.0482e-03,  5.3161e-04,  6.2154e-03],\n",
      "        [ 1.6032e-02,  3.3631e-02,  1.0520e-03, -4.4497e-03],\n",
      "        [-5.7099e-02, -1.0369e-01,  7.1369e-04,  2.4184e-02],\n",
      "        [-4.7789e-02, -7.8099e-02, -1.4425e-05,  1.2007e-02],\n",
      "        [-4.6336e-02, -7.5795e-02,  8.5686e-05,  1.1793e-02]])\n"
     ]
    }
   ],
   "source": [
    "for param in policy_net.parameters():\n",
    "    print(param[:5])\n",
    "    print(param.grad.data[:5])\n",
    "    #print(param.grad.data.clamp_(-0.03, 0.03))\n",
    "    print(param.grad.data[:5])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0677,  0.0258,  0.4143,  0.4048,  0.3801], grad_fn=<SliceBackward0>)\n",
      "tensor([-0.0714,  0.0243,  0.4158,  0.4046,  0.3803], grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method epsilon_greedy_policy.decay_value_update of <__main__.epsilon_greedy_policy object at 0x000001D534C0BB50>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(target_net.layer1.bias[:5])\n",
    "print(policy_net.layer1.bias[:5])\n",
    "action_policy.decay_value_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\24573\\AppData\\Local\\Temp\\ipykernel_714676\\909987632.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  DQN_model = torch.load('DQN_train_from_random_stable.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.02999075  0.19501142 -0.04022024 -0.31982896]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.02609052  0.3906824  -0.04661682 -0.62491965]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.01827687  0.19624119 -0.05911521 -0.34727502]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.01435205  0.00200772 -0.06606071 -0.0738035 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.01431189  0.19801147 -0.06753679 -0.38657558]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.01035166  0.00391    -0.0752683  -0.11592784]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.01027346 -0.1900573  -0.07758685  0.15209134]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.01407461 -0.3839875  -0.07454503  0.41932386]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.02175436 -0.18789278 -0.06615855  0.10410275]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.02551221 -0.3820073  -0.06407649  0.3752011 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.03315236 -0.57616335 -0.05657247  0.64701194]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.04467563 -0.38030073 -0.04363223  0.33706453]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.05228164 -0.57477546 -0.03689094  0.6156753 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.06377715 -0.37915805 -0.02457744  0.31160527]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.07136031 -0.5739214  -0.01834533  0.596437  ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.08283874 -0.37854758 -0.00641659  0.29803237]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.0904097  -0.18333475 -0.00045594  0.00333269]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.09407639 -0.37845016 -0.00038929  0.29587173]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.10164539 -0.18332265  0.00552815  0.00306605]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.10531184 -0.37852344  0.00558947  0.29748803]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.11288232 -0.18348162  0.01153923  0.00657316]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.11655194  0.01147295  0.01167069 -0.28244677]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.11632249 -0.1838135   0.00602175  0.01389406]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.11999875 -0.3790213   0.00629964  0.30847082]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.12757918 -0.18398967  0.01246905  0.01778127]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.13125898  0.01095126  0.01282468 -0.2709416 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.13103995 -0.18435133  0.00740585  0.02575855]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.13472697 -0.37957868  0.00792102  0.32076886]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.14231855 -0.18457043  0.01433639  0.03059442]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.14600997  0.01034302  0.01494828 -0.25753096]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.1458031  -0.18498912  0.00979766  0.03982914]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.14950289 -0.3802502   0.01059425  0.33558714]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.15710789 -0.1852806   0.01730599  0.04626383]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.1608135   0.00958897  0.01823127 -0.24090905]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.16062172 -0.1857886   0.01341308  0.0574683 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.16433749  0.00913849  0.01456245 -0.23095271]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.16415472 -0.18618849  0.0099434   0.0662879 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.1678785   0.0087895   0.01126915 -0.22324131]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.1677027  -0.1864917   0.00680433  0.07297494]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.17143254  0.00853205  0.00826383 -0.21755345]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.17126189 -0.18670705  0.00391276  0.07772475]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.17499603 -0.38188487  0.00546725  0.37163958]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.18263373 -0.18684103  0.01290004  0.08068554]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.18637055  0.00809365  0.01451376 -0.20789963]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.18620868 -0.18723279  0.01035576  0.08932608]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.18995333  0.0077392   0.01214228 -0.20007169]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.18979855 -0.18755428  0.00814085  0.09641669]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.19354963  0.00745004  0.01006918 -0.19368674]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19340064 -0.18781449  0.00619545  0.10215551]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.19715692  0.00721813  0.00823856 -0.18856636]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19701256 -0.18802072  0.00446723  0.10670408]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20077297  0.00703694  0.00660131 -0.18456611]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20063224 -0.18817884  0.00290999  0.11019194]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20439582  0.00690129  0.00511383 -0.18157148]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20425779 -0.18829346  0.0014824   0.11272028]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20802365  0.00680722  0.00373681 -0.17949459]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-2.07887515e-01 -1.88368008e-01  1.46914099e-04  1.14364825e-01]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21165487 -0.38349205  0.00243421  0.4070941 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.21932472 -0.18840471  0.01057609  0.1151796 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22309281  0.00656411  0.01287968 -0.17414798]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22296153 -0.18873978  0.00939672  0.12257009]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22673632  0.00624629  0.01184813 -0.16713351]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22661139 -0.18904324  0.00850546  0.12926348]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23039226  0.00595585  0.01109073 -0.16072398]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23027314 -0.18932311  0.00787625  0.13543704]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2340596   0.00568515  0.01058499 -0.15475067]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2339459  -0.18958674  0.00748997  0.14125268]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23773764  0.00542713  0.01031503 -0.14905791]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2376291  -0.189841    0.00733387  0.14686127]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24142592  0.00517517  0.01027109 -0.14349897]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24132241 -0.19009236  0.00740111  0.15240653]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24512427  0.00492284  0.01044925 -0.13793235]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2450258  -0.19034721  0.0076906   0.15802875]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24883275  0.0046638   0.01085117 -0.1322181 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24873947 -0.1906119   0.00820681  0.16386838]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2525517   0.00439162  0.01148418 -0.12621427]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25246388 -0.19089295  0.00895989  0.17006956]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25628173  0.00409961  0.01236129 -0.11977338]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25619975 -0.19119725  0.00996582  0.17678365]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26002368  0.00378068  0.01350149 -0.11273881]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25994807 -0.1915321   0.01124671  0.18417299]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26377872  0.00342713  0.01493017 -0.10494091]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.26371017 -0.19190556  0.01283136  0.19241478]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2675483   0.0030305   0.01667965 -0.09619293]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.26748767 -0.19232649  0.01475579  0.20170538]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2713342   0.00258135  0.0187899  -0.08628651]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.27128258 -0.19280483  0.01706417  0.21226493]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.27513868  0.00206905  0.02130947 -0.0749867 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.27509728 -0.1933518   0.01980973  0.22434254]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.27896434  0.00148149  0.02429659 -0.06202639]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2789347   0.19624682  0.02305606 -0.34694564]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.27500975  0.00080463  0.01611714 -0.04708241]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.27499366 -0.19454467  0.0151755   0.25064173]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.27888456  0.00035731  0.02018833 -0.03721618]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2788774   0.19518404  0.01944401 -0.32346174]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-2.7497375e-01 -2.0931549e-04  1.2974772e-02 -2.4710938e-02]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.27497792  0.19472419  0.01248055 -0.3132721 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.27108344 -0.00057332  0.00621511 -0.01667948]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.27109492 -0.19578384  0.00588152  0.2779579 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2750106  -0.00074629  0.01144068 -0.01286422]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.27502552  0.19420974  0.0111834  -0.30191565]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.27114132 -0.00106981  0.00514508 -0.00572679]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.27116272 -0.19626518  0.00503055  0.28857502]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.275088   -0.00121531  0.01080205 -0.00251708]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.27511233  0.19375007  0.01075171 -0.29177237]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2712373  -0.00152352  0.00491626  0.00428204]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2712678   0.19352758  0.0050019  -0.28684568]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.26739722 -0.00166535 -0.00073501  0.00741058]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.26743054 -0.19677675 -0.0005868   0.29986152]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2713661  -0.00164644  0.00541043  0.00699357]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.27139902  0.1933975   0.0055503  -0.2839774 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-2.6753107e-01 -1.8031701e-03 -1.2924963e-04  1.0450879e-02]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-2.6756713e-01 -1.9692327e-01  7.9767953e-05  3.0309302e-01]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2715056  -0.00180245  0.00614163  0.01043525]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.27154163  0.19323088  0.00635033 -0.2803036 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.267677   -0.00198108  0.00074426  0.01437542]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.26771665 -0.1971137   0.00103177  0.3072931 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.27165893 -0.00200646  0.00717763  0.01493572]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.27169904  0.19301182  0.00747635 -0.27547395]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2678388  -0.00221599  0.00196687  0.0195576 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26788312  0.1928777   0.00235802 -0.27250412]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.26402557 -0.00227782 -0.00309206  0.02092161]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.26407114 -0.1973553  -0.00267363  0.31262735]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26801825 -0.00219536  0.00357892  0.01910245]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26806214  0.19287509  0.00396096 -0.27244914]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.26420465 -0.00230316 -0.00148802  0.02148045]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2642507  -0.19740374 -0.00105841  0.31369352]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2681988  -0.00226673  0.00521546  0.02067699]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26824412  0.19278005  0.005629   -0.27035585]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-2.6438850e-01 -2.4217800e-03  2.2188346e-04  2.4097167e-02]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26443696  0.19269699  0.00070383 -0.26851574]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.260583   -0.002435   -0.00466649  0.02438909]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2606317  -0.19748972 -0.00417871  0.31559604]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2645815  -0.0023085   0.00213321  0.02159823]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26462767  0.1927828   0.00256518 -0.2704109 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.26077202 -0.00237566 -0.00284304  0.02308001]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.26081952 -0.19745673 -0.00238144  0.31486458]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26476866 -0.00230094  0.00391585  0.02143157]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26481467  0.19276464  0.00434448 -0.2700133 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2609594  -0.00241904 -0.00105578  0.02403673]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2610078   0.19271804 -0.00057505 -0.26897913]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25715342 -0.0023957  -0.00595463  0.02352238]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2572013  -0.19743176 -0.00548418  0.31432062]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26114997 -0.00223211  0.00080223  0.01991322]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26119462  0.19287832  0.0012005  -0.2725165 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25733703 -0.00226074 -0.00424983  0.02054484]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25738224 -0.19732149 -0.00383894  0.31188387]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26132867 -0.00214505  0.00239874  0.01799273]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26137158  0.19294243  0.00275859 -0.2739324 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25751272 -0.00221878 -0.00272005  0.01961932]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2575571  -0.19730163 -0.00232767  0.3114428 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26150313 -0.00214659  0.00390119  0.0180267 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.26154608  0.1929192   0.00426172 -0.2734228 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2576877  -0.0022633  -0.00120673  0.02060123]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25773296 -0.19736792 -0.00079471  0.31290317]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2616803  -0.00223466  0.00546335  0.01996973]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.261725    0.19280852  0.00586275 -0.27098444]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25786883 -0.0023966   0.00044306  0.02354183]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25791678  0.192719    0.0009139  -0.26900128]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25406238 -0.00241599 -0.00446613  0.02396976]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2541107  -0.19747362 -0.00398673  0.31524023]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2580602  -0.0022951   0.00231807  0.02130269]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25810608  0.19279353  0.00274412 -0.27064794]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2542502  -0.00236747 -0.00266883  0.02289922]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25429755 -0.19745104 -0.00221085  0.3147389 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25824657 -0.00229767  0.00408393  0.02135957]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25829253  0.19276547  0.00451112 -0.27003205]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25443724 -0.00242056 -0.00088952  0.0240703 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25448564  0.19271414 -0.00040812 -0.26889315]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25063136 -0.00240198 -0.00578598  0.02366103]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2506794  -0.19744049 -0.00531276  0.31451282]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2546282  -0.00224326  0.0009775   0.02015916]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25467306  0.19286466  0.00138068 -0.2722152 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25081578 -0.00227696 -0.00406362  0.02090289]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25086132 -0.1973404  -0.00364556  0.31230092]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25480813 -0.00216671  0.00260045  0.01847053]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25485146  0.19291785  0.00296986 -0.2733908 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2509931  -0.00224635 -0.00249795  0.02022736]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.251038   -0.19733238 -0.0020934   0.31212112]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25498468 -0.00218067  0.00414902  0.01877872]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25502828  0.19288154  0.00452459 -0.27259225]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.25117067 -0.00230469 -0.00092725  0.0215143 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25121674  0.19283055 -0.00049697 -0.27146104]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24736014 -0.00228431 -0.00592619  0.0210651 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24740583 -0.19732077 -0.00550488  0.31187236]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25135225 -0.00212083  0.00073256  0.01745847]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25139466  0.19299062  0.00108173 -0.27499324]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24753484 -0.00214676 -0.00441813  0.01803067]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24757779 -0.19720507 -0.00405752  0.30931637]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2515219  -0.00202554  0.00212881  0.01535657]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2515624   0.1930658   0.00243594 -0.27665395]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24770108 -0.00209081 -0.00309714  0.01679629]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24774289 -0.1971682  -0.00276121  0.30850044]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25168625 -0.00200702  0.0034088   0.01494797]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2517264   0.19306588  0.00370775 -0.2766575 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24786508 -0.00210877 -0.0018254   0.01719255]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24790725 -0.1972045  -0.00148154  0.309299  ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25185135 -0.00206147  0.00470444  0.01614919]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.25189257  0.1929927   0.00502742 -0.27504572]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24803272 -0.00220062 -0.0004735   0.0192186 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-2.4807674e-01  1.9292812e-01 -8.9123372e-05 -2.7361369e-01]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24421817 -0.00219256 -0.0055614   0.01904114]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24426202 -0.19723432 -0.00518057  0.3099642 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2482067  -0.00203893  0.00101871  0.01565198]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24824749  0.19306839  0.00133175 -0.27670935]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24438612 -0.00207253 -0.00420244  0.01639331]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24442758 -0.19713396 -0.00387457  0.30774736]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24837025 -0.00195702  0.00228038  0.01384502]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24840939  0.19313215  0.00255728 -0.27811757]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24454674 -0.00202619 -0.00300508  0.01537084]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24458727 -0.19710492 -0.00269766  0.3071041 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24852937 -0.00194463  0.00344442  0.01357164]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24856827  0.19312777  0.00371586 -0.27802256]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2447057  -0.002047   -0.00184459  0.01583004]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24474664 -0.19714245 -0.00152799  0.3079304 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24868949 -0.00199876  0.00463062  0.01476598]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24872947  0.19305648  0.00492593 -0.27645233]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24486834 -0.00213541 -0.00060311  0.01778015]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-2.4491104e-01 -1.9724870e-01 -2.4750942e-04  3.1027272e-01]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24885602 -0.00212323  0.00595795  0.01751175]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24889849  0.19291277  0.00630818 -0.27328545]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24504024 -0.00229861  0.00084247  0.02138042]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24508621  0.19281125  0.00127008 -0.2710366 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24122998 -0.00232881 -0.00415065  0.02204666]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24127656 -0.19739099 -0.00370972  0.31341714]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24522437 -0.00221639  0.00255862  0.01956658]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2452687   0.19286878  0.00294996 -0.27230796]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24141133 -0.00229514 -0.0024962   0.02130392]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24145722 -0.19738121 -0.00207013  0.3131982 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24540485 -0.00222983  0.00419384  0.01986316]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24544945  0.19283172  0.0045911  -0.2714936 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.24159281 -0.00235543 -0.00083877  0.02263382]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24163993  0.19277854 -0.00038609 -0.27031362]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23778436 -0.0023379  -0.00579237  0.0222475 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23783112 -0.19737631 -0.00534742  0.31309724]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24177864 -0.00217859  0.00091453  0.01873273]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24182221  0.19293024  0.00128918 -0.27366152]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2379636  -0.00221009 -0.00418405  0.01942774]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23800781 -0.19727178 -0.00379549  0.31078762]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24195324 -0.00209596  0.00242026  0.01691013]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24199516  0.1929912   0.00275846 -0.2750082 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23813534 -0.00217    -0.0027417   0.01854348]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23817874 -0.19725253 -0.00237083  0.3103601 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24212378 -0.00209688  0.00383637  0.01693043]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24216573  0.19296984  0.00417498 -0.27453962]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23830633 -0.00221143 -0.00131581  0.01945718]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23835056 -0.19731449 -0.00092667  0.31172466]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24229684 -0.00217934  0.00530782  0.01874964]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.24234043  0.19286609  0.00568282 -0.2722539 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-2.3848312e-01 -2.3364888e-03  2.3773871e-04  2.2215983e-02]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23852985  0.19278206  0.00068206 -0.2703919 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2346742  -0.00234963 -0.00472578  0.02250605]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2347212  -0.19740349 -0.00427566  0.3136942 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23866926 -0.00222089  0.00199822  0.01966594]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23871368  0.19287235  0.00239154 -0.27238587]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23485623 -0.00228365 -0.00305617  0.02105041]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2349019  -0.19736163 -0.00263517  0.3127675 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23884913 -0.00220224  0.00362018  0.01925471]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23889318  0.1928676   0.00400528 -0.27228382]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23503584 -0.00231127 -0.0014404   0.02165969]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23508206 -0.19741254 -0.0010072   0.3138878 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2390303  -0.00227625  0.00527055  0.02088742]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23907584  0.19276972  0.0056883  -0.27012795]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23522043 -0.00243294  0.00028574  0.02434366]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2352691   0.19268492  0.00077262 -0.2682491 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2314154  -0.00244806 -0.00459237  0.02467742]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23146436 -0.19750385 -0.00409882  0.31590787]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23541443 -0.00232375  0.00221934  0.02193514]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2354609   0.1927663   0.00265804 -0.27004674]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23160559 -0.00239348 -0.00274289  0.02347337]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23165345 -0.19747598 -0.00227342  0.31528962]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23560297 -0.00232173  0.00403237  0.0218906 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2356494   0.19274217  0.00447018 -0.26951733]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.23179457 -0.00244329 -0.00092017  0.02457215]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23184343  0.19269185 -0.00042872 -0.26840097]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2279896  -0.00242399 -0.00579674  0.02414671]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22803807 -0.19746234 -0.00531381  0.31499508]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23198733 -0.00226509  0.00098609  0.0206411 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23203263  0.1928427   0.00139891 -0.27173054]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22817577 -0.00229918 -0.0040357   0.02139328]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22822176 -0.19736302 -0.00360783  0.31280017]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23216902 -0.00218986  0.00264817  0.01898163]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23221281  0.19289401  0.00302781 -0.27286458]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22835493 -0.00227101 -0.00242949  0.02077178]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22840035 -0.19735804 -0.00201405  0.3126872 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23234752 -0.00220745  0.00423969  0.01936977]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.23239166  0.19285344  0.00462709 -0.27197248]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2285346  -0.00233423 -0.00081236  0.02216625]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22858128  0.19279936 -0.00036904 -0.27077287]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22472529 -0.00231732 -0.00578449  0.02179364]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22477163 -0.19735584 -0.00534862  0.31264588]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22871876 -0.0021581   0.0009043   0.01828098]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22876191  0.19295087  0.00126992 -0.2741165 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2249029  -0.00218918 -0.00421241  0.0189667 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22494668 -0.19725047 -0.00383308  0.31031758]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22889169 -0.00207411  0.00237327  0.01642829]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22893317  0.19301373  0.00270184 -0.2755049 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2250729  -0.00214667 -0.00280826  0.01802897]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22511584 -0.19722824 -0.00244768  0.30982453]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2290604  -0.0020715   0.00374881  0.01637068]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22910182  0.19299649  0.00407622 -0.2751271 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2252419  -0.00218338 -0.00142632  0.01883868]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22528556 -0.19728485 -0.00104954  0.31107125]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22923127 -0.00214796  0.00517188  0.01805751]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22927423  0.19289944  0.00553303 -0.27298915]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-2.2541623e-01 -2.3010224e-03  7.3247298e-05  2.1433763e-02]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22546226  0.19281988  0.00050192 -0.27122605]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22160585 -0.00230923 -0.0049226   0.02161514]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22165205 -0.19736025 -0.0044903   0.31274086]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22559924 -0.00217461  0.00176452  0.01864524]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22564274  0.192922    0.00213743 -0.27348045]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2217843  -0.00223039 -0.00333218  0.01987587]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22182891 -0.1973044  -0.00293466  0.3115056 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22577499 -0.00214076  0.00329545  0.01789861]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22581781  0.19293377  0.00365342 -0.27374274]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22195913 -0.00224011 -0.00182144  0.02009023]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22200394 -0.1973359  -0.00141963  0.31219792]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22595066 -0.00219375  0.00482433  0.01906762]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22599453  0.19285868  0.00520568 -0.27208927]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.22213736 -0.00233716 -0.00023611  0.02223099]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-2.2218409e-01  1.9278817e-01  2.0851393e-04 -2.7052644e-01]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21832834 -0.00233675 -0.00520201  0.02222226]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21837507 -0.19738372 -0.00475757  0.31325936]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22232275 -0.00219431  0.00150762  0.01907985]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22236663  0.19290599  0.00188921 -0.27312702]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21850851 -0.00224287 -0.00357333  0.02015117]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21855336 -0.1973134  -0.0031703   0.31170455]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22249964 -0.00214642  0.00306379  0.01802348]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22254257  0.19293146  0.00342426 -0.2736912 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21868393 -0.00223918 -0.00204957  0.02006976]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21872872 -0.19733168 -0.00164817  0.31210533]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22267535 -0.00218629  0.00459394  0.01890307]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.22271907  0.19286948  0.004972   -0.2723269 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21886168 -0.00232306 -0.00047454  0.02192007]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-2.1890815e-01  1.9280569e-01 -3.6139732e-05 -2.7091256e-01]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21505204 -0.00231575 -0.00545439  0.02175898]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21509835 -0.19735906 -0.00501921  0.312716  ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.21904553 -0.00216596  0.00123511  0.01845442]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.21908885  0.19293825  0.0016042  -0.27383855]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21523009 -0.00220655 -0.00387257  0.0193499 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21527421 -0.19727275 -0.00348558  0.31080848]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.21921967 -0.00210131  0.00273059  0.01702834]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.21926169  0.19298138  0.00307116 -0.2747918 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21540207 -0.00218426 -0.00242468  0.01885819]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21544576 -0.19727135 -0.00204751  0.3107751 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.21939118 -0.00212029  0.00416799  0.01744717]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.21943359  0.19294164  0.00451693 -0.2739178 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21557476 -0.00224447 -0.00096142  0.02018635]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21561964 -0.19735262 -0.0005577   0.31256577]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2195667  -0.00222273  0.00569362  0.01970702]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.21961115  0.1928171   0.00608776 -0.27117407]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2157548  -0.00239118  0.00066428  0.02342272]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.21580264  0.19272123  0.00113273 -0.26905054]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21194822 -0.00241686 -0.00424828  0.02398944]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21199654 -0.19747762 -0.00376849  0.31532896]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2159461  -0.0023022   0.00253809  0.02145997]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.21599214  0.19278325  0.00296729 -0.2704211 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21213648 -0.00238091 -0.00244113  0.02319627]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2121841  -0.19746777 -0.00197721  0.315108  ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.21613345 -0.00231771  0.00432495  0.02180217]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2161798   0.19274195  0.004761   -0.26951304]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.21232496 -0.00244762 -0.00062926  0.02466772]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-2.1237391e-01  1.9268335e-01 -1.3590933e-04 -2.6821369e-01]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20852025 -0.00243666 -0.00550018  0.02442637]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20856899 -0.19747931 -0.00501166  0.31536886]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.21251857 -0.00228632  0.00129572  0.02110965]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2125643   0.19281702  0.00171791 -0.27116418]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20870796 -0.0023294  -0.00370537  0.02206009]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20875454 -0.19739802 -0.00326417  0.31357163]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2127025  -0.00222972  0.00300727  0.01986108]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2127471   0.19284898  0.00340449 -0.2718715 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20889013 -0.00232139 -0.00203294  0.02188327]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20893654 -0.19741413 -0.00159528  0.31392407]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.21288483 -0.00226949  0.0046832   0.02073848]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.21293022  0.192785    0.00509797 -0.27046317]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20907453 -0.00240934 -0.00031129  0.02382332]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-2.0912270e-01  1.9271708e-01  1.6517719e-04 -2.6895779e-01]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20526837 -0.00240723 -0.00521398  0.02377721]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20531651 -0.19745402 -0.00473843  0.3148105 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20926559 -0.0022649   0.00155778  0.02063702]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20931089  0.19283468  0.00197052 -0.271554  ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2054542  -0.00231533 -0.00346056  0.02174978]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2055005  -0.19738749 -0.00302557  0.31333885]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20944825 -0.00222256  0.00324121  0.0197033 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2094927   0.19285275  0.00363527 -0.27195522]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20563565 -0.00232088 -0.00180383  0.02187206]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20568207  0.1928269  -0.00136639 -0.27137944]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20182553 -0.00227553 -0.00679398  0.02087219]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20187104 -0.19729939 -0.00637653  0.3114038 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-2.0581703e-01 -2.0871821e-03 -1.4845737e-04  1.6716769e-02]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-2.0585877e-01  1.9303690e-01  1.8587799e-04 -2.7601299e-01]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20199803 -0.0020877  -0.00533438  0.01672855]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20203978 -0.19713275 -0.00499981  0.30772367]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20598245 -0.00193991  0.00115466  0.01346812]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20602123  0.19316545  0.00142402 -0.27885026]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20215793 -0.00197678 -0.00415298  0.01428145]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20219746 -0.19703892 -0.00386735  0.3056512 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20613824 -0.00186208  0.00224567  0.01175109]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20617549  0.19322759  0.00248069 -0.28022245]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20231093 -0.00192965 -0.00312376  0.01324185]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20234953 -0.19700667 -0.00285892  0.30493757]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20628966 -0.00184409  0.00323983  0.01135437]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20632654  0.19323124  0.00346692 -0.28030458]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20246191 -0.00193999 -0.00213917  0.01346977]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20250072 -0.1970312  -0.00186978  0.305477  ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20644134 -0.00188265  0.00423976  0.01220497]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.206479    0.19317824  0.00448386 -0.27913725]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20261542 -0.00200738 -0.00109888  0.0149565 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20265557  0.19313031 -0.00079975 -0.27807292]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19879296 -0.00198022 -0.00636121  0.01435765]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19883257 -0.19701037 -0.00607406  0.30502677]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-2.0277278e-01 -1.8023904e-03  2.6478105e-05  1.0434436e-02]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-2.0280883e-01  1.9331919e-01  2.3516682e-04 -2.8224012e-01]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19894245 -0.00180612 -0.00540964  0.01051695]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19897857 -0.19685008 -0.0051993   0.30148816]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20291556 -0.00165441  0.00083047  0.00717004]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20294866  0.19345562  0.00097387 -0.28525075]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19907954 -0.0016802  -0.00473115  0.00773917]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19911315 -0.19673398 -0.00457636  0.2989256 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20304783 -0.0015471   0.00140215  0.00480291]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20307878  0.19355471  0.00149821 -0.2874373 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19920768 -0.00158857 -0.00425054  0.00571778]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19923945 -0.19664931 -0.00413618  0.2970566 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20317243 -0.00146864  0.00180495  0.00307205]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2032018   0.19362739  0.00186639 -0.28904083]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19932926 -0.00152114 -0.00391443  0.00423014]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19935969 -0.19658673 -0.00382982  0.29567546]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20329142 -0.00141039  0.00208368  0.00178712]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20331962  0.19368161  0.00211943 -0.29023764]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.199446   -0.00147049 -0.00368533  0.00311297]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19947541 -0.1965394  -0.00362307  0.29463086]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20340618 -0.00136598  0.00226955  0.00080747]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20343351  0.19372335  0.0022857  -0.29115853]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19955905 -0.00143112 -0.00353747  0.00224441]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19958766 -0.19650216 -0.00349258  0.29380912]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-2.0351771e-01 -1.3305891e-03  2.3835998e-03  2.6737023e-05]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20354432  0.1937571   0.00238413 -0.2919032 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19966918 -0.00139877 -0.00345393  0.00153072]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19969715 -0.19647102 -0.00342331  0.29312187]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20362657 -0.00130042  0.00243912 -0.00063874]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20365258  0.19378646  0.00242635 -0.2925511 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19977686 -0.00137    -0.00342467  0.00089608]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19980425 -0.19644266 -0.00340675  0.29249653]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2037331  -0.00127231  0.00244318 -0.0012589 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20375855  0.19381452  0.002418   -0.29316998]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19988227 -0.00134182 -0.0034454   0.00027457]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.1999091  -0.19641419 -0.00343991  0.29186845]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20383738 -0.00124336  0.00239746 -0.0018974 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20386225 -0.19639961  0.00235951  0.29154098]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20779024 -0.00131139  0.00819033 -0.00039684]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20781647  0.19369215  0.0081824  -0.2904844 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20394263 -0.00154551  0.00237271  0.00476788]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20397353  0.19354233  0.00246807 -0.2871655 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20010269 -0.00161473 -0.00327524  0.00629483]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.200135   -0.19668956 -0.00314935  0.29794258]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20406878 -0.00152286  0.0028095   0.00426807]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20409924  0.1935587   0.00289487 -0.2875271 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20022807 -0.00160442 -0.00285568  0.00606743]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20026015 -0.1966853  -0.00273433  0.297848  ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20419386 -0.00152448  0.00322263  0.00430396]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20422435  0.19355111  0.00330871 -0.28736043]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20035332 -0.00161788 -0.0024385   0.00636418]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20038567 -0.19670478 -0.00231121  0.29827675]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20431978 -0.00154995  0.00365432  0.00486579]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20435077  0.1935194   0.00375164 -0.28666192]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20048039 -0.00165585 -0.0019816   0.00720188]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2005135  -0.19674933 -0.00183756  0.29925895]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20444849 -0.00160123  0.00414761  0.00599704]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20448051  0.19346099  0.00426756 -0.28537437]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.2006113  -0.00172156 -0.00143993  0.00865144]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20064573 -0.19682284 -0.0012669   0.30087972]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20458218 -0.00168285  0.00475069  0.00779749]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20461585  0.19337066  0.00490664 -0.28338277]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20074843 -0.00182094 -0.00076101  0.01084365]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.20078485 -0.19693197 -0.00054414  0.30328637]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20472348 -0.00180227  0.00552159  0.01043188]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20475952  0.19324006  0.00573022 -0.2805038 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-2.0089473e-01 -1.9631558e-03  1.2014719e-04  1.3980884e-02]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.200934    0.19315708  0.00039976 -0.27866414]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19707085 -0.00197058 -0.00517352  0.01414485]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19711027 -0.19701795 -0.00489062  0.30519098]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20105062 -0.00182665  0.0012132   0.0109697 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20108715  0.19327788  0.00143259 -0.2813302 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19722159 -0.00186448 -0.00419401  0.01180422]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19725889 -0.19692603 -0.00395793  0.30316094]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2011974  -0.0017479   0.00210529  0.0092324 ]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20123236  0.1933438   0.00228994 -0.28278553]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.1973655  -0.00181074 -0.00336577  0.01061875]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.1974017  -0.19688426 -0.0031534   0.30223784]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2013394  -0.00171751  0.00289136  0.00856207]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20137374  0.19336286  0.0030626  -0.2832072 ]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19750649 -0.00180264 -0.00260154  0.01044008]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19754253 -0.19688718 -0.00239274  0.30230105]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20148028 -0.00173122  0.00365328  0.00886447]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.2015149   0.19333816  0.00383057 -0.28266355]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.19764814 -0.00183823 -0.0018227   0.01122504]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.1976849  -0.19693398 -0.0015982   0.30333233]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20162359 -0.0017893   0.00446845  0.01014579]\n",
      "1\n",
      "Action:1 Reward:1.0 next_state [-0.20165937  0.19326828  0.00467136 -0.28112394]\n",
      "0\n",
      "Action:0 Reward:1.0 next_state [-0.197794   -0.00191999 -0.00095112  0.01302865]\n",
      "End! with 499 rewards\n",
      "Terminated with cumulated rewards: 499\n"
     ]
    }
   ],
   "source": [
    "operation = 'test'\n",
    "if operation == 'test':\n",
    "    import time \n",
    "    import gymnasium as gym\n",
    "    import torch\n",
    "    import torch.nn.functional as F\n",
    "    from itertools import count\n",
    "    from torch import nn\n",
    "\n",
    "    class DQN(nn.Module):\n",
    "\n",
    "        def __init__(self, n_observations, n_actions):\n",
    "            super(DQN, self).__init__()\n",
    "            self.layer1 = nn.Linear(n_observations, 128)\n",
    "            self.layer2 = nn.Linear(128, 128)\n",
    "            self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "        # Called with either one element to determine next action, or a batch\n",
    "        # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.layer1(x))\n",
    "            x = F.relu(self.layer2(x))\n",
    "            return self.layer3(x)\n",
    "\n",
    "    #env.render_mode = 'human'\n",
    "    DQN_model = torch.load('DQN_train_from_random_stable.pt')\n",
    "    cumulated_rewards = 0\n",
    "\n",
    "    env = gym.make(\"CartPole-v1\", render_mode = 'human')\n",
    "    #env = gym.make('Acrobot-v1', render_mode=\"human\")\n",
    "    state, _ = env.reset()\n",
    "    #env.render()\n",
    "\n",
    "    for j in count():\n",
    "        #action = action_policy.take_action_policy(policy_net, state, verbose=True)\n",
    "        with torch.no_grad():\n",
    "            action = DQN_model(torch.tensor(state, dtype = torch.float32).unsqueeze(0)).max(1).indices.numpy()[0]\n",
    "        print(action)\n",
    "        next_state, reward, terminated, _, __ = env.step(int(action))\n",
    "        print('Action:{} Reward:{} next_state {}'.format(action, reward, next_state))\n",
    "        if terminated or _ == True:\n",
    "            print('End! with {} rewards'.format(j))\n",
    "            break\n",
    "        else:\n",
    "            cumulated_rewards += 1\n",
    "            state = next_state\n",
    "        time.sleep(0.1)\n",
    "    print('Terminated with cumulated rewards: {}'.format(cumulated_rewards))\n",
    "    env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
